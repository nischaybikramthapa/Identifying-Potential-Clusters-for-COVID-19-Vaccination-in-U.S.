{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T02:46:26.085018Z",
     "start_time": "2020-09-22T02:46:26.035129Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import urlopen, Request\n",
    "from datetime import datetime, timedelta,date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T03:13:50.226976Z",
     "start_time": "2020-09-22T03:13:49.957538Z"
    }
   },
   "outputs": [],
   "source": [
    "#Useful functions\n",
    "def calculate_sum(state_df,state_name,column):\n",
    "    \n",
    "    '''selects the total number from state specified in the argument\n",
    "    For e.g: If we want total from Alabama state of Confirmed case column it returns a number'''\n",
    "    \n",
    "    total = state_df[state_df['Province_State']==state_name][column].values[0]\n",
    "    return total\n",
    "\n",
    "def calculate_state_to_county(county_df,state_df,state_name,first_column,second_column):\n",
    "    new_df = county_df[county_df['State']==state_name]\n",
    "    first_col_total = calculate_sum(state_df,state_name,first_column)\n",
    "    second_col_total = calculate_sum(state_df,state_name,second_column)\n",
    "\n",
    "    return (round((new_df[first_column]/first_col_total)*second_col_total)).tolist()\n",
    "def drop_and_melt(us_confirmed_raw,us_deaths_raw):\n",
    "    #Drop uncessary columns\n",
    "    confirmed_df = us_confirmed_raw.drop(['UID','iso2',\"iso3\",'code3','Country_Region','Combined_Key'],axis=1)\n",
    "\n",
    "    #Drop uncessary columns\n",
    "\n",
    "    deaths_df = us_deaths_raw.drop(['UID','iso2',\"iso3\",'code3','Country_Region','Combined_Key'],axis=1)\n",
    "\n",
    "    #Extract variable with dates\n",
    "    dates = confirmed_df.columns[6:]\n",
    "\n",
    "    #Melt the dataset from row into columns\n",
    "    us_confirmed = pd.melt(confirmed_df,id_vars = ['Admin2','Province_State','FIPS','Lat','Long_'],value_vars=dates, var_name='Date', value_name='Confirmed')\n",
    "    us_deaths = pd.melt(deaths_df,id_vars = ['Admin2','Province_State','FIPS','Lat','Long_'],value_vars=dates, var_name='Date', value_name='Deaths')\n",
    "    us_confirmed['Date'] = pd.to_datetime(us_confirmed['Date'],format = '%m/%d/%y')\n",
    "    us_deaths['Date'] = pd.to_datetime(us_deaths['Date'], format = '%m/%d/%y')\n",
    "    return us_confirmed, us_deaths\n",
    "\n",
    "def calculate_average_new_cases(df):\n",
    "    \n",
    "    yesterday = df['Date'].max().strftime('%m/%d/%y')\n",
    "    days_14 = (df['Date'].max()- timedelta(days = 14)).strftime('%m/%d/%y') \n",
    "    df = df.set_index('Date')\n",
    "    days_14 = df.loc[days_14:yesterday]\n",
    "    days_14.sort_values(by = ['Province_State','Admin2'])\n",
    "    state_county = days_14[['Province_State','Admin2']]\n",
    "    state_county = state_county.drop_duplicates()\n",
    "    state_county = state_county.reset_index()\n",
    "    state = []\n",
    "    county = []\n",
    "    average  = []\n",
    "    for i in range(0,len(state_county)):\n",
    "        temp_state = state_county.loc[i,'Province_State']\n",
    "        temp_county = state_county.loc[i,'Admin2']\n",
    "        mean_average = days_14[(days_14['Province_State'] == temp_state) & (days_14['Admin2']==temp_county)]['Confirmed'].diff().mean()\n",
    "        state.append(temp_state)\n",
    "        county.append(temp_county)\n",
    "        average.append(mean_average)\n",
    "    average_df = pd.DataFrame({'state':state,'county':county,'average':average})\n",
    "    return average_df\n",
    "\n",
    "def prepare_data(us_confirmed,us_deaths,pop_mob_df_raw,us_land):\n",
    "    #Filter data from recent date\n",
    "    latest = us_confirmed['Date'].max().strftime('%Y-%m-%d')\n",
    "    counties_confirmed = us_confirmed[us_confirmed['Date']==latest]\n",
    "    counties_deaths = us_deaths[us_deaths['Date']==latest]['Deaths']\n",
    "\n",
    "    #Concatenate two dataframes\n",
    "    us_counties_df_raw = pd.concat([counties_confirmed,counties_deaths],axis=1)\n",
    "\n",
    "    #Remove missing counties as they are from other US territories\n",
    "    us_counties_df_raw = us_counties_df_raw[us_counties_df_raw['Admin2'].notnull()]\n",
    "\n",
    "    #Remove values which are not in US states\n",
    "    not_us_states = ['Puerto Rico','District of Columbia']\n",
    "    us_counties_df_raw = us_counties_df_raw[~us_counties_df_raw['Province_State'].isin(not_us_states)]\n",
    "\n",
    "    #     unused_cols = ['Country_Region','Last_Update','FIPS','UID','ISO3','USAState','TotalRecovered']\n",
    "    #     us_states_df = us_states_df.drop(columns=unused_cols,axis=1)\n",
    "\n",
    "    #Remove unknown county names\n",
    "    us_counties_df_raw = us_counties_df_raw[~us_counties_df_raw['Admin2'].str.contains(r'Out .*|Unassigned',regex=True,na=False)]\n",
    "\n",
    "    # Match county names for two columns\n",
    "    pop_mob_df_raw['county'] = pop_mob_df_raw['county'].str.split(' County')\n",
    "    pop_mob_df_raw.loc[:, 'County'] = pop_mob_df_raw.county.map(lambda x: x[0])\n",
    "\n",
    "    #Drop extra column\n",
    "    pop_mob_df_raw = pop_mob_df_raw.drop('county',axis=1)\n",
    "\n",
    "    #Filter values which are not considered as county\n",
    "    pop_mob_df_raw = pop_mob_df_raw[pop_mob_df_raw['state']!='District of Columbia']\n",
    "    pop_mob_df_raw = pop_mob_df_raw.dropna(axis=1)\n",
    "    #Create stopwords which do not match county names from JHU data\n",
    "    stopwords = ['Census Area','Parish','Municipality','Parish','city and Borough','city',' and Borough','Borough','City']\n",
    "\n",
    "    #Remove stopwords\n",
    "    for stopword in stopwords:\n",
    "        pop_mob_df_raw['County']  = pop_mob_df_raw['County'].str.replace(stopword,'').str.strip()\n",
    "\n",
    "    pop_mob_df_raw = pop_mob_df_raw.sort_values(by='population2019')\n",
    "    pop_mob_df_raw = pop_mob_df_raw.drop_duplicates(subset= ['state','County'],keep='last')\n",
    "\n",
    "    us_counties_df = us_counties_df_raw.merge(pop_mob_df_raw,how=\"inner\",left_on=[\"Province_State\",\"Admin2\"],right_on=[\"state\",\"County\"])\n",
    "\n",
    "    #Drop duplicate columns\n",
    "    cols_to_be_removed = ['Admin2','Province_State']\n",
    "    us_counties_df = us_counties_df.drop(columns=cols_to_be_removed,axis=1)\n",
    "\n",
    "    #Rename and reorder colunmns\n",
    "    us_counties_df = us_counties_df.rename(columns = {'state':'State','Long_':'Long','population2019':'Population'})\n",
    "    columns = ['Date','State','County','FIPS','Lat','Long','Population','Confirmed','Deaths','Recovered','Mortality_Rate']\n",
    "    us_counties_df = us_counties_df.reindex(columns,axis=1)\n",
    "\n",
    "    # Add land area to master dataframe\n",
    "\n",
    "    #Remove whitespaces\n",
    "    us_land['State'] = us_land['State'].str.strip()\n",
    "    us_land = us_land.sort_values(by='Area')\n",
    "    us_land = us_land.drop_duplicates(subset= ['State','County'],keep='last')\n",
    "    #Merge dataset on common columns\n",
    "    us_counties_df = us_counties_df.merge(us_land,how=\"left\",on=[\"State\",\"County\"])\n",
    "    return us_counties_df\n",
    "\n",
    "def clean_us_states(world_us_states_df):\n",
    "    #Remove unwanted values by index\n",
    "    world_us_states_df = world_us_states_df.drop(world_us_states_df.index[[0,63]])\n",
    "\n",
    "    #Extract only useful columns\n",
    "    world_us_states_df = world_us_states_df[['USAState','TotalRecovered']]\n",
    "\n",
    "    #Merge two dataframe on state names\n",
    "    us_states_df = us_states_df_raw.merge(world_us_states_df,how='inner',left_on='Province_State',right_on='USAState')\n",
    "\n",
    "    #Fill missing values\n",
    "    us_states_df['Recovered'] = us_states_df['Recovered'].fillna(us_states_df['TotalRecovered'],axis=0)\n",
    "\n",
    "    #Remove values which are not in US states\n",
    "    remove_states = ['Guam','Puerto Rico','Northern Mariana Islands']\n",
    "    us_states_df = us_states_df[~us_states_df['Province_State'].isin(remove_states)]\n",
    "    unused_cols = ['Country_Region','Last_Update','FIPS','UID','ISO3','USAState','TotalRecovered']\n",
    "    us_states_df = us_states_df.drop(columns=unused_cols,axis=1)\n",
    "    return us_states_df\n",
    "\n",
    "def create_new_features(us_states_df,us_counties_df):\n",
    "    #Create list of states\n",
    "    states = list(us_states_df['Province_State'])\n",
    "    recovered_list = []\n",
    "    test_list = []\n",
    "\n",
    "    for state in states:\n",
    "        recovered_list.append(calculate_state_to_county(us_counties_df,us_states_df,state,'Confirmed','Recovered'))\n",
    "    #Convert lists of list into single list\n",
    "    flattened = [values for sublist in recovered_list for values in sublist]\n",
    "\n",
    "    #Add list values into dataframe corsspending to each row\n",
    "    us_counties_df['Recovered'] = flattened\n",
    "\n",
    "    #Create new column for mortality rates\n",
    "    us_counties_df['Mortality_Rate'] = (us_counties_df['Deaths'] *100) / us_counties_df['Confirmed']\n",
    "\n",
    "    # Convert land area square miles into square kms\n",
    "    miles_to_km = 0.38610\n",
    "    us_counties_df['Land Area'] = us_counties_df['Area']/miles_to_km\n",
    "    us_counties_df = us_counties_df.drop(columns='Area',axis=1)\n",
    "\n",
    "    return us_counties_df\n",
    "def validate_data(us_counties_df):\n",
    "    df = us_counties_df.copy()\n",
    "\n",
    "    df['Active'] = df['Confirmed'] - df['Recovered'] - df['Deaths']\n",
    "    df['Active'][df['Active']<0] = 0\n",
    "    #Death rate tried with confirmed cases but values were ununsual and not relaiable\n",
    "    # source: https://www.cdc.gov/csels/dsepd/ss1978/lesson3/section3.html\n",
    "    df['Death_per_1000_pop'] = (df['Deaths'] /df['Population'])*1000\n",
    "    df['Infection_Rate'] = (df['Active']/df['Population'])*100\n",
    "    reg_url = 'https://www.indexmundi.com/facts/united-states/quick-facts/louisiana/land-area#table'\n",
    "    req = Request(url=reg_url, headers=headers)\n",
    "    html = urlopen(req).read()\n",
    "    lous_county_df = pd.read_html(html)[0]\n",
    "    lous_county_df['County'] = lous_county_df['County'].str.replace('Parish','').str.strip()\n",
    "    lousiana = df[df['State']=='Louisiana']\n",
    "    merged_lous = lousiana.merge(lous_county_df,on='County')\n",
    "    merged_lous = merged_lous.drop('Land Area',axis=1)\n",
    "    miles_to_km = 0.38610\n",
    "    merged_lous['Value'] = merged_lous['Value']/miles_to_km\n",
    "    merged_lous = merged_lous.rename(columns={'Value':'Land Area'})\n",
    "    df = df[df['State']!='Louisiana']\n",
    "    df = pd.concat([df,merged_lous],axis=0)\n",
    "    #change the merge code to this one later\n",
    "    df.loc[df['County']=='Kusilvak','Land Area'] = 50953\n",
    "    df.loc[df['County']=='Oglala Lakota','Land Area']  = 5431\n",
    "    df.loc[df['County']=='Denali','Land Area'] = 33092\n",
    "    df.loc[df['County']=='Skagway','Land Area'] = 28267\n",
    "    df.loc[df['County']=='Wrangell','Land Area'] =9004\n",
    "    df.loc[df['County']=='Yakutat','Land Area'] = 24509\n",
    "    df.loc[df['County']=='Broomfield','Land Area'] = 86.89\n",
    "    df.loc[df['County']=='Fairfax','Land Area'] = 1052\n",
    "    df.loc[df['County']=='Fairfax','Population'] = 1010000\n",
    "    df['Pop_density'] = df['Population']/df['Land Area']\n",
    "    df['Active_per_1000_pop'] = (df['Active']/df['Population'])*1000\n",
    "    df['Recovered_per_1000_pop'] = (df['Recovered']/df['Population'])*1000\n",
    "    return df\n",
    "def merge_average_df(df,average_df):\n",
    "    final_df = df.merge(average_df,how='left',left_on=['State','County'],right_on=['state','county'])\n",
    "    return final_df\n",
    "\n",
    "def drop_unsed_columns(df):\n",
    "    df = df.drop(columns=['state','county'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T03:14:03.750546Z",
     "start_time": "2020-09-22T03:13:54.881455Z"
    }
   },
   "outputs": [],
   "source": [
    "# US Sate level data from JHU latest retrieval\n",
    "us_states_df_raw = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/08-20-2020.csv')\n",
    "\n",
    "# Us confirmed Cases County level from JHU\n",
    "us_confirmed_raw = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')\n",
    "\n",
    "# Us deaths County level from JHU\n",
    "us_deaths_raw = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv')\n",
    "\n",
    "# From Worldometer\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "reg_url = 'https://www.worldometers.info/coronavirus/country/us/'\n",
    "req = Request(url=reg_url, headers=headers)\n",
    "html = urlopen(req).read()\n",
    "world_us_states_df = pd.read_html(html)[0]\n",
    "\n",
    "# From google developers contaning state names\n",
    "us_states = pd.read_html('https://developers.google.com/public-data/docs/canonical/states_csv')[0]\n",
    "\n",
    "#From google mobility and census \n",
    "pop_mob_df_raw = pd.read_csv('pop_mob_us.csv',index_col = 0)\n",
    "#From census.gov\n",
    "us_land = pd.read_csv('us_area.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T03:15:39.052370Z",
     "start_time": "2020-09-22T03:14:18.784825Z"
    }
   },
   "outputs": [],
   "source": [
    "us_confirmed, us_deaths = drop_and_melt(us_confirmed_raw,us_deaths_raw)\n",
    "average_df = calculate_average_new_cases(us_confirmed)\n",
    "us_counties_df = prepare_data(us_confirmed,us_deaths,pop_mob_df_raw,us_land)\n",
    "us_states_df = clean_us_states(world_us_states_df)\n",
    "us_counties_df = create_new_features(us_states_df,us_counties_df)\n",
    "cleaned_df = validate_data(us_counties_df)\n",
    "df = merge_average_df(cleaned_df,average_df)\n",
    "final_df = drop_unsed_columns(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
